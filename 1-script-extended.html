<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>script-extended</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="1-script-extended_files/libs/clipboard/clipboard.min.js"></script>
<script src="1-script-extended_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="1-script-extended_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="1-script-extended_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="1-script-extended_files/libs/quarto-html/popper.min.js"></script>
<script src="1-script-extended_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="1-script-extended_files/libs/quarto-html/anchor.min.js"></script>
<link href="1-script-extended_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="1-script-extended_files/libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="1-script-extended_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="1-script-extended_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="1-script-extended_files/libs/bootstrap/bootstrap-d6a003b94517c951b2d65075d42fb01b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="extended-notes-double-debiased-machine-learning-talk" class="level1">
<h1>Extended Notes: Double / Debiased Machine Learning Talk</h1>
<p>These notes back each slide with more details and references to the Chernozhukov et al.&nbsp;(2018) paper <em>“Double / Debiased Machine Learning for Treatment and Structural Parameters”</em> and Victor Chernozhukov’s talk.</p>
<hr>
<section id="slide-2-the-problem-causal-effects-with-many-covariates" class="level2">
<h2 class="anchored" data-anchor-id="slide-2-the-problem-causal-effects-with-many-covariates">Slide 2 — The problem: causal effects with many covariates</h2>
<ul>
<li>The paper’s intro sets up the problem as inference on a low-dimensional parameter (_0) in the presence of high-dimensional or highly complex nuisance parameters (_0), estimated via ML. This is explicitly stated in the abstract and Section 1.:contentReference<span data-index="17">oaicite:17</span></li>
<li>The point that ML is good for prediction but not automatically for causal parameters is stressed in the talk, where Chernozhukov emphasizes that good prediction does not guarantee good estimation of a causal parameter and can even be misleading.:contentReference<span data-index="18">oaicite:18</span></li>
</ul>
<hr>
</section>
<section id="slide-3-prediction-vs.-causal-estimation" class="level2">
<h2 class="anchored" data-anchor-id="slide-3-prediction-vs.-causal-estimation">Slide 3 — Prediction vs.&nbsp;causal estimation</h2>
<ul>
<li>The general moment-condition language ([(W;_0,_0)]=0) is introduced in Section 2 (Moment condition / estimating equations framework).:contentReference<span data-index="19">oaicite:19</span></li>
<li>The distinction between prediction and causal estimation is illustrated in the Introduction: ML methods are used to estimate complex nuisances, but naive plug-in leads to biased estimators of (_0).:contentReference<span data-index="20">oaicite:20</span></li>
<li>The talk transcript also highlights two main points: (i) ML can predict very well, (ii) naive use produces poor estimators for causal parameters.:contentReference<span data-index="21">oaicite:21</span></li>
</ul>
<hr>
</section>
<section id="slide-4-why-econometricians-love-moment-conditions" class="level2">
<h2 class="anchored" data-anchor-id="slide-4-why-econometricians-love-moment-conditions">Slide 4 — Why econometricians love moment conditions</h2>
<ul>
<li>The paper uses a GMM-style viewpoint: target parameters are defined by population moment conditions, then estimated by solving empirical analogues. This is formalized in Section 2.1.:contentReference<span data-index="22">oaicite:22</span></li>
<li>Examples like OLS, IV, and GMM are standard; the paper also references semi-parametric literature where efficient scores come from such moment conditions (e.g.&nbsp;Chamberlain 1987, Newey 1994).:contentReference<span data-index="23">oaicite:23</span></li>
</ul>
<hr>
</section>
<section id="slide-5-moment-conditions-in-the-partially-linear-model" class="level2">
<h2 class="anchored" data-anchor-id="slide-5-moment-conditions-in-the-partially-linear-model">Slide 5 — Moment conditions in the partially linear model</h2>
<ul>
<li>The PLR model is introduced as Example 1.1 in Section 1:<br>
[ Y = D_0 + g_0(X) + U, [UX,D]=0, ] [ D = m_0(X)+V, [VX]=0. ]:contentReference<span data-index="24">oaicite:24</span></li>
<li>The naive regression-adjustment moment ([(Y - D_0 - g_0(X))D]=0) corresponds to treating (g_0) as known and regressing (Y-g_0(X)) on (D).</li>
<li>The propensity-style moment<br>
([(Y - D_0)(D - m_0(X))]=0) is related to reweighting based on deviations from the propensity score. This is less central in the paper but natural in the PLR setting.</li>
<li>The orthogonal score<br>
((W;,g,m)=(Y-D-g(X))(D-m(X))) is explicitly given in Section 4.1 as a key example of an orthogonal moment.:contentReference<span data-index="25">oaicite:25</span></li>
</ul>
<hr>
</section>
<section id="slide-7-naive-regression-adjustment-bias-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="slide-7-naive-regression-adjustment-bias-decomposition">Slide 7 — Naive regression adjustment: bias decomposition</h2>
<ul>
<li>The plug-in estimator and its bias decomposition are spelled out in the Introduction. The paper considers sample splitting: estimating (g_0) on an auxiliary sample and then forming [ _0 = (D_i<sup>2)</sup>{-1} (D_i (Y_i - g_0(X_i))). ]:contentReference<span data-index="26">oaicite:26</span></li>
<li>The scaled estimation error decomposes as [ (_0 - _0) = a+b, ] where [ a = (E[D^2])^{-1}D_i U_i, ] [ b (E[D^2])^{-1}m_0(X_i){g_0(X_i) - g_0(X_i)}. ]:contentReference<span data-index="27">oaicite:27</span></li>
<li>The paper notes that ML methods yield rates like (n^{-_g}) with (_g &lt; 1/2), implying that the term (b) diverges in general at ()-scale, so the estimator fails to be ()-consistent. This is discussed under “Regularization bias”.:contentReference<span data-index="28">oaicite:28</span></li>
</ul>
<hr>
</section>
<section id="slide-8-orthogonal-residual-score-bias-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="slide-8-orthogonal-residual-score-bias-decomposition">Slide 8 — Orthogonal (residual) score: bias decomposition</h2>
<ul>
<li>The orthogonalized construction replaces (D) by its residual (V = D - m_0(X)), estimated as (V=D-m(X)), and defines a DML estimator [ _0 = (V_i D_i)^{-1} (V_i (Y_i - g(X_i))), ] which can be rearranged into the residual regression form used in the slides.:contentReference<span data-index="29">oaicite:29</span></li>
<li>The decomposition [ (_0 - _0) = a^* + b^* + c^* ] is sketched in the paper:
<ul>
<li>(a^* = (E[V^2])<sup>{-1}n</sup>{-1/2}V_iU_i)<br>
</li>
<li>(b^* = (E[V^2])<sup>{-1}n</sup>{-1/2}(m(X_i) - m_0(X_i))(g(X_i) - g_0(X_i)))<br>
</li>
<li>(c^*) is the remainder, controlled via sample splitting.</li>
</ul></li>
<li>The key is that (b^*) depends on a product of estimation errors and is of order (,n^{-(_m+_g)}), which can vanish for (_m+_g&gt;1/2).:contentReference<span data-index="30">oaicite:30</span></li>
</ul>
<hr>
</section>
<section id="slide-9-neyman-orthogonality-definition-plr-example" class="level2">
<h2 class="anchored" data-anchor-id="slide-9-neyman-orthogonality-definition-plr-example">Slide 9 — Neyman orthogonality: definition &amp; PLR example</h2>
<ul>
<li>Definition 2.1 gives Neyman orthogonality formally: the Gateaux derivative of the moment w.r.t.&nbsp;the nuisance at ((_0,_0)) is zero for all directions in a realization set.:contentReference<span data-index="31">oaicite:31</span></li>
<li>The notation in the paper is [ __P[(W;_0,_0)][-_0] = 0. ]</li>
<li>For the PLR score ((W;,g,m) = (Y-D-g(X))(D-m(X))), the paper notes that this orthogonality condition holds w.r.t.&nbsp;(=(g,m)), which accounts for the improved robustness (the derivative of the moment w.r.t.&nbsp;misspecification in (g,m) vanishes).:contentReference<span data-index="32">oaicite:32</span></li>
</ul>
<hr>
</section>
<section id="slide-10-residual-interpretation-iv-style-view" class="level2">
<h2 class="anchored" data-anchor-id="slide-10-residual-interpretation-iv-style-view">Slide 10 — Residual interpretation &amp; IV-style view</h2>
<ul>
<li>The residual interpretation (Y = Y-g(X)), (D = D-m(X))<br>
and the estimator [ = ] corresponds to a regression of residualized (Y) on residualized (D).</li>
<li>The paper points out that the DML estimator can be interpreted as a linear IV estimator where the instrument is the residualized treatment (V = D-m(X)). This is noted explicitly in the discussion about ‘double prediction’ and connections to optimal instruments.:contentReference<span data-index="33">oaicite:33</span></li>
<li>The talk also highlights this “double prediction” viewpoint: one ML problem for (Y) given (X), another for (D) given (X), then regress one residual on the other.:contentReference<span data-index="34">oaicite:34</span></li>
</ul>
<hr>
</section>
<section id="slide-11-sample-splitting-and-cross-fitting" class="level2">
<h2 class="anchored" data-anchor-id="slide-11-sample-splitting-and-cross-fitting">Slide 11 — Sample splitting and cross-fitting</h2>
<ul>
<li>The problematic remainder terms without sample splitting involve expressions like [ V_i(g(X_i) - g_0(X_i)), ] where (g) is estimated on the same sample, so the dependence structure can cause these terms to fail to vanish at the desired rate.:contentReference<span data-index="35">oaicite:35</span></li>
<li>The paper explains that with sample splitting, we estimate nuisances on an auxiliary sample, and conditionally on that sample, terms like the above have mean zero and variance determined by the squared nuisance error. The variance then goes to zero as the nuisance error shrinks.:contentReference<span data-index="36">oaicite:36</span></li>
<li>Cross-fitting (swapping main and auxiliary samples or using K-fold versions) restores efficiency while maintaining these favorable properties. This is formalized via DML1 and DML2 in Section 3, but in the slides we avoid naming those explicitly to keep things lighter.:contentReference<span data-index="37">oaicite:37</span></li>
</ul>
<hr>
</section>
<section id="slide-1213-algorithm-for-plr-dml" class="level2">
<h2 class="anchored" data-anchor-id="slide-1213-algorithm-for-plr-dml">Slide 12–13 — Algorithm for PLR DML</h2>
<ul>
<li>Definitions 3.1 and 3.2 give formal DML algorithms:
<ul>
<li>DML1 averages fold-specific solutions of orthogonal estimating equations.</li>
<li>DML2 defines one global estimator solving a single pooled orthogonal estimating equation built from cross-fitted nuisances.:contentReference<span data-index="38">oaicite:38</span></li>
</ul></li>
<li>The slides give a simplified operational version: K-fold split, fit nuisances out-of-fold, construct residuals, regress residualized outcome on residualized treatment per fold, then average.</li>
<li>Variance estimation uses the empirical influence function of the orthogonal score; Theorem 3.1 and 3.2 provide asymptotic linearity and show how to estimate the asymptotic variance.:contentReference<span data-index="39">oaicite:39</span></li>
</ul>
<hr>
</section>
<section id="slide-14-what-double-ml-delivers-high-level" class="level2">
<h2 class="anchored" data-anchor-id="slide-14-what-double-ml-delivers-high-level">Slide 14 — What double ML delivers (high level)</h2>
<ul>
<li>Theorem 3.1 and 3.3 show that under approximate Neyman orthogonality and appropriate rate conditions on the nuisance estimators, DML estimators are asymptotically linear and Gaussian: [ (- _0) = (W_i) + o_p(1), ] where () is the influence function.:contentReference<span data-index="40">oaicite:40</span></li>
<li>Under homoscedasticity and with efficient scores, Corollary 3.2 notes that DML achieves the semiparametric efficiency bound. For the PLR model, the orthogonal score we used is efficient under homoscedasticity.:contentReference<span data-index="41">oaicite:41</span></li>
</ul>
<hr>
</section>
<section id="slide-15-simulation-prediction-vs-causal-estimation" class="level2">
<h2 class="anchored" data-anchor-id="slide-15-simulation-prediction-vs-causal-estimation">Slide 15 — Simulation: prediction vs causal estimation</h2>
<ul>
<li>The simulations in the paper and in the talk consider designs where (g_0) is particularly suitable for random forests. Figure 1 in the paper compares the conventional (non-orthogonal) ML estimator with the DML estimator:
<ul>
<li>The conventional estimator’s histogram is biased and poorly approximated by a normal distribution.</li>
<li>The DML estimator’s histogram is centered at zero and well approximated by its normal limit.</li>
</ul></li>
<li>The talk also presents Monte Carlo results illustrating this contrast, emphasizing that prediction performance and causal performance can diverge.:contentReference<span data-index="43">oaicite:43</span></li>
</ul>
<hr>
</section>
<section id="slide-16-application-401k-eligibility-and-savings" class="level2">
<h2 class="anchored" data-anchor-id="slide-16-application-401k-eligibility-and-savings">Slide 16 — Application: 401(k) eligibility and savings</h2>
<ul>
<li>Section 6.2 of the paper provides an application to 401(k) eligibility and net financial assets. The outcome and covariates are defined as in the slide:
<ul>
<li>Net financial assets include IRAs, 401(k), checking, bonds, stocks, mutual funds, minus non-mortgage debt.</li>
<li>Covariates include age, income, family size, education, marital status, two-earner status, DB pension status, IRA participation, home ownership.:contentReference<span data-index="44">oaicite:44</span></li>
</ul></li>
<li>The identification strategy follows Poterba et al.&nbsp;(1994): conditional on these covariates, eligibility can be treated as exogenous.</li>
<li>The paper reports DML estimates of the ATE of eligibility on assets, with magnitudes in the several thousand dollars range, robust across a variety of learners. The exact numbers depend on the specification but are in the ($7)–($9)k ballpark.:contentReference<span data-index="45">oaicite:45</span></li>
</ul>
<hr>
</section>
<section id="slide-17-beyond-plr-ate-atte-pliv-late" class="level2">
<h2 class="anchored" data-anchor-id="slide-17-beyond-plr-ate-atte-pliv-late">Slide 17 — Beyond PLR: ATE, ATTE, PLIV, LATE</h2>
<ul>
<li><strong>ATE/ATTE</strong>: Section 5.1 develops orthogonal scores for average treatment effects and average treatment effects on the treated under unconfoundedness. These scores combine outcome regression and propensity score and are designed to be orthogonal.:contentReference<span data-index="46">oaicite:46</span></li>
<li><strong>Partially linear IV model</strong>: Section 4.2 analyzes the model [ Y = D_0 + g_0(X) + U,&nbsp;[UX,Z]=0; D = m_0(X,Z) + V,&nbsp;[VX,Z]=0. ] This enforces the exclusion restriction: conditional on (X), (Z) only affects (Y) through (D). Orthogonal scores use residualized outcome and residualized instrument / endogenous variable.:contentReference<span data-index="47">oaicite:47</span></li>
<li><strong>LATE</strong>: Section 5.2 provides orthogonal scores for local average treatment effects with binary (D) and (Z). Nuisances include conditional means (_0(z,x)=[YZ=z,X=x]), (m_0(z,x)=[DZ=z,X=x]), and the instrument propensity (p_0(X)=[ZX]).:contentReference<span data-index="48">oaicite:48</span></li>
</ul>
<hr>
</section>
<section id="slide-18-what-dml-does-not-fix" class="level2">
<h2 class="anchored" data-anchor-id="slide-18-what-dml-does-not-fix">Slide 18 — What DML does not fix</h2>
<ul>
<li>The paper repeatedly stresses that DML works under the same identification assumptions as the underlying causal models:
<ul>
<li>PLR: conditional exogeneity given (X).</li>
<li>ATE/ATTE: unconfoundedness given (X).</li>
<li>PLIV/LATE: valid instruments with appropriate structural assumptions.:contentReference<span data-index="49">oaicite:49</span></li>
</ul></li>
<li>DML does not address unobserved confounding; it only allows flexible nonparametric estimation of the observed-nuisance structure. The need for good research design and careful control selection is highlighted especially in the applications section.:contentReference<span data-index="50">oaicite:50</span></li>
</ul>
<hr>
</section>
<section id="slide-19-evidence-from-method-evaluation-studies" class="level2">
<h2 class="anchored" data-anchor-id="slide-19-evidence-from-method-evaluation-studies">Slide 19 — Evidence from method evaluation studies</h2>
<ul>
<li>While the specific ‘Estimating Causal Effects with Double Machine Learning – A Method Evaluation’ paper is not in the uploaded files, its findings are consistent with broader simulation evidence:
<ul>
<li>DML with rigid learners (e.g.&nbsp;plain lasso in misspecified designs) can inherit bias similar to OLS.</li>
<li>DML with flexible learners tends to reduce bias in nonlinear confounding scenarios.</li>
</ul></li>
<li>The DML paper’s empirical and simulation results show that choice of learner inside DML affects performance: see the 401(k) example where different ML methods give similar but not identical estimates, and the simulation figures where non-orthogonal estimators perform poorly even with strong predictors.</li>
<li>This supports the message that DML is not a magic bullet: ML choice heavily influences finite-sample performance.</li>
</ul>
<hr>
</section>
<section id="slide-20-checklist-take-home-message" class="level2">
<h2 class="anchored" data-anchor-id="slide-20-checklist-take-home-message">Slide 20 — Checklist &amp; take-home message</h2>
<ul>
<li>The general abstract theory in Sections 3 and 5 shows that as long as nuisance estimators achieve certain rates and orthogonality holds, DML yields valid asymptotic inference for low-dimensional (_0).:contentReference<span data-index="52">oaicite:52</span></li>
<li>In practice, the workflow ‘identify estimand, derive orthogonal score, choose ML, cross-fit, do sensitivity checks’ is exactly what the paper suggests via its repeated pattern across models (PLR, PLIV, ATE/ATTE, LATE).</li>
<li>Victor Chernozhukov’s talk also emphasizes this as a reusable template: two prediction problems for nuisances, one orthogonal estimating equation, sample splitting and averaging.:contentReference<span data-index="53">oaicite:53</span></li>
</ul>
<hr>
</section>
<section id="meta-talk-structure-choices-vs.-guidelines" class="level2">
<h2 class="anchored" data-anchor-id="meta-talk-structure-choices-vs.-guidelines">Meta: talk-structure choices vs.&nbsp;guidelines</h2>
<ul>
<li>The structure of the talk (early statement of key idea, emphasis on a single central idea, use of one running model with one main algorithm) follows typical advice for research talks:
<ul>
<li>Communicate one key idea; do not try to present all technical details.:contentReference<span data-index="54">oaicite:54</span></li>
<li>Prefer depth over breadth, and use examples (PLR, 401(k)) to ground intuition.</li>
<li>Keep must-have parts (motivation, key result, main example) within the allotted time, and be ready to truncate advanced material if needed.</li>
</ul></li>
</ul>
<p>These notes should put you in a good position to answer deeper questions about:</p>
<ul>
<li>why naive plug-in fails (()-bias decomposition),</li>
<li>how orthogonality is defined and checked,</li>
<li>why cross-fitting is necessary,</li>
<li>how the method extends beyond PLR,</li>
<li>and what the empirical implications are.</li>
</ul>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>